from mesonet.mask_functions import atlas_to_mask, applyMask
import numpy as np
import pandas as pd
import cv2
import scipy.io
import skimage.io as io
from skimage.transform import PiecewiseAffineTransform, warp
import os
import fnmatch


def find_peaks(img):
    maxLocArr = []
    img = cv2.imread(str(img), 0)
    im = img.copy()
    x_min = int(np.around(im.shape[0]/2))
    im1 = im[:, x_min:im.shape[0]]
    im2 = im[:, 0:x_min]
    (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(im1)
    (minVal2, maxVal2, minLoc2, maxLoc2) = cv2.minMaxLoc(im2)
    maxLoc = list(maxLoc)
    maxLoc[0] = maxLoc[0] + x_min
    maxLoc = tuple(maxLoc)
    maxLocArr.append(maxLoc)
    if maxVal2 == maxVal:
        maxLocArr.append(maxLoc2)
    return maxLocArr


def atlas_from_mat(input_file):
    file = input_file
    mat = scipy.io.loadmat(file)
    mat = mat['cdata']
    ret, thresh = cv2.threshold(mat, 5, 255, cv2.THRESH_BINARY_INV)
    return thresh


def getMaskContour(mask_dir, atlas_img, heatmap_pts, circle_pts, cwd, n, sensory):
    c_landmarks = np.empty([0, 2])
    c_atlas_landmarks = np.empty([0, 2])
    mask = cv2.imread(mask_dir, cv2.IMREAD_GRAYSCALE)
    atlas_to_warp = atlas_img
    # mask = cv2.resize(mask, (atlas_to_warp.shape[0], atlas_to_warp.shape[1]))
    mask = np.uint8(mask)
    mask_new, cnts, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)
    for cnt in cnts:
        cnt = cnt[:, 0, :]
        cnt = np.asarray(cnt).astype('float32')
        c_landmarks = np.concatenate((c_landmarks, cnt))
        c_atlas_landmarks = np.concatenate((c_atlas_landmarks, cnt))
    c_landmarks = np.concatenate((c_landmarks, heatmap_pts))
    c_atlas_landmarks = np.concatenate((c_atlas_landmarks, circle_pts))
    tform = PiecewiseAffineTransform()
    tform.estimate(c_atlas_landmarks, c_landmarks)
    dst = warp(atlas_to_warp, tform, output_shape=(512, 512))
    io.imsave(os.path.join(cwd, "mask_{}.png".format(n)), mask)
    return dst


def atlasBrainMatch(brain_img_dir, sensory_img_dir, landmark_atlas_img, sensory_atlas_img, coords_input, sensory_match,
                    mat_save, threshold):
    """
    Align and overlap brain atlas onto brain image based on four landmark locations in the brain image and the atlas.
    :param brain_img_dir: The directory containing each brain image to be used
    :param atlas_img: The path to the atlas to be overlaid onto each image
    :param coords_input: Predicted locations of the four landmarks on the brain image from the file generated by
    DeepLabCut.
    """
    # load brain images folder
    brain_img_arr = []
    peak_arr = []
    for num, file in enumerate(os.listdir(brain_img_dir)):
        if fnmatch.fnmatch(file, "*.png"):
            brain_img_arr.append(os.path.join(brain_img_dir, file))
    i_coord, j_coord = np.array([(100, 256, 413, 256), (148, 254, 148, 446)])
    # i_coord, j_coord = coords_from_mat(os.path.join(cwd, 'atlases/landmarks_notransparent.png'))

    if sensory_match:
        for num, file in enumerate(os.listdir(sensory_img_dir)):
            if fnmatch.fnmatch(file, "{}.png".format(num)):
                peak = find_peaks(os.path.join(sensory_img_dir, file))
                peak_arr.append(peak)
        peak_arr_flat = []
        for x in peak_arr:
            for y in x:
                peak_arr_flat.append(y)

    pts = []
    pts2 = []
    pts3 = []
    pts4 = []
    sub_pts = []
    sub_pts2 = []
    sub_pts3 = []
    sub_pts4 = []

    coords = pd.read_csv(coords_input)
    x_coord = coords.iloc[2:, 1::3]
    y_coord = coords.iloc[2:, 2::3]
    for i in range(0, len(x_coord)):
        x_coord_flat = x_coord.iloc[i].values.astype('float32')
        y_coord_flat = y_coord.iloc[i].values.astype('float32')
        # 0 = left, 1 = bregma, 2 = right, 3 = lambda
        for j in [0, 3, 2, 1]:
            sub_pts.append([x_coord_flat[j], y_coord_flat[j]])
        # 1 = left, 2 = bregma, 3 = right, 0 = lambda
        for j in [0, 3, 2, 1]:
            sub_pts2.append([i_coord[j], j_coord[j]])
        pts.append(sub_pts)
        pts2.append(sub_pts2)
        sub_pts = []
        sub_pts2 = []
    pts, pts2 = np.asarray(pts).astype('float32'), np.asarray(pts2).astype('float32')
    if sensory_match:
        k_coord, m_coord = np.array([(189, 323, 435, 348), (315, 315, 350, 460)])
        coords_peak = peak_arr_flat
        for img in brain_img_arr:
            for j in [1, 0, 3, 2]:  # Get peak values from heatmaps
                sub_pts3.append([coords_peak[j][0], coords_peak[j][1]])
            for j in [0, 1, 2, 3]:  # Get circle locations
                sub_pts4.append([k_coord[j], m_coord[j]])
            pts3.append(sub_pts3)
            pts4.append(sub_pts4)
            sub_pts3 = []
            sub_pts4 = []
        pts3, pts4 = np.asarray(pts3).astype('float32'), np.asarray(pts4).astype('float32')

    for n, br in enumerate(brain_img_arr):
        cwd = os.getcwd()
        output_mask_path = os.path.join(cwd, "../output_mask")
        # Output folder for transparent masks and masks overlaid onto brain image
        output_overlay_path = os.path.join(cwd, "../output_overlay")
        if not os.path.isdir(output_mask_path):
            os.mkdir(output_mask_path)
        if not os.path.isdir(output_overlay_path):
            os.mkdir(output_overlay_path)
        im = atlas_from_mat(os.path.join(cwd, '../../atlases/atlas_512_512.mat'))
        io.imsave(os.path.join(cwd, "../output_mask/im.png".format(n)), im)
        cv2.imread(os.path.join(cwd, "../output_mask/im.png".format(n)), cv2.IMREAD_GRAYSCALE)
        atlas_mask_dir = os.path.join(cwd, "../../atlases/atlas_mask.png")
        atlas_mask = cv2.imread(atlas_mask_dir, cv2.IMREAD_UNCHANGED)
        atlas_mask = cv2.resize(atlas_mask, (im.shape[0], im.shape[1]))
        mask_dir = os.path.join(cwd, "../output_mask/{}.png".format(n))
        print("mask dir: {}".format(mask_dir))
        M = cv2.getAffineTransform(pts2[n][0:3], pts[n][0:3])
        atlas_warped = cv2.warpAffine(im, M, (512, 512))
        atlas_mask_warped = cv2.warpAffine(atlas_mask, M, (512, 512))
        dst = getMaskContour(mask_dir, atlas_warped, pts[n], pts2[n], cwd, n, False)
        if sensory_match:
            dst = getMaskContour(mask_dir, atlas_warped, pts3[n], pts4[n], cwd, n, True)
        dst = cv2.resize(dst, (im.shape[0], im.shape[1]))
        atlas_mask_warped = cv2.resize(atlas_mask_warped, (im.shape[0], im.shape[1]))
        atlas_path = os.path.join(output_mask_path, '{}_atlas.png'.format(str(n)))
        mask_warped_path = os.path.join(output_mask_path, '{}_mask_warped.png'.format(str(n)))
        io.imsave(atlas_path, dst)
        io.imsave(mask_warped_path, atlas_mask_warped)
        atlas_to_mask(atlas_path, mask_dir, mask_warped_path, output_mask_path, n)
    applyMask(brain_img_dir, output_mask_path, output_overlay_path, output_overlay_path, mat_save, threshold)
