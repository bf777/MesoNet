{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mesonet_demo_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14ZoP1l75j5tW8fJx4kMu42FA4t2Jq0l0",
      "authorship_tag": "ABX9TyMUS+vbxWta+I65bu34UOaI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf777/MesoNet/blob/master/mesonet_demo_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBeYLFh1y43a"
      },
      "source": [
        "# MesoNet\n",
        "Welcome to MesoNet, a toolbox for segmenting mesoscale calcium images! This notebook will take you through all the steps needed to process your own calcium imaging dataset using our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ySs_sMAzwMo"
      },
      "source": [
        "# Clone MesoNet repository\n",
        "!git clone https://github.com/bf777/MesoNet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWqA1QrmVu5U"
      },
      "source": [
        "# Prepare inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utG7t2c7JTqv"
      },
      "source": [
        "!mkdir /content/mesonet_inputs/\n",
        "!mkdir /content/mesonet_inputs/pipeline1_2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFZjRHCPvUL4"
      },
      "source": [
        "# Utility to install mesonet package and associated requirements (will be replaced with pip later)\n",
        "!pip install matplotlib==3.1.3\n",
        "\n",
        "# Install DeepLabCut for pose estimation\n",
        "!pip install deeplabcut"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX2xRSlOG8BW"
      },
      "source": [
        "Because of how DeepLabCut operates, you now need to restart your runtime (under the Runtime menu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgL7qiElE8O8"
      },
      "source": [
        "# NOTE: Rerun this cell and the following two cells if you're getting an error when importing MesoNet\n",
        "%cd MesoNet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcmr-pE1yR75"
      },
      "source": [
        "# Install MesoNet\n",
        "!python setup.py install\n",
        "\n",
        "# Reinstall OpenCV to address compatibility issue\n",
        "!pip install opencv-python==4.4.0.46\n",
        "\n",
        "# Reinstall h5py\n",
        "!pip install h5py==2.10.0\n",
        "\n",
        "# pip install mesonet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlkSR2Y1DMt-"
      },
      "source": [
        "# Use tensorflow 1.x (supported by DeepLabCut)\n",
        "# %tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import os\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyqTdwum9zFL"
      },
      "source": [
        "We will now pull information from the OSF repository containing the DeepLabCut and U-Net models for our code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEycrQjx9yeS"
      },
      "source": [
        "!pip install osfclient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nHcGUo5-RZ6"
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 6_Landmark_estimation_model/atlas-DongshengXiao-2020-08-03.zip mesonet_inputs/atlas-DongshengXiao-2020-08-03.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfMh09FNB8KX"
      },
      "source": [
        "!unzip -q mesonet_inputs/atlas-DongshengXiao-2020-08-03.zip -d /content/mesonet_inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmNgWKOJA4Ou"
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 7_U-Net_model/DongshengXiao_brain_bundary.hdf5 MesoNet/mesonet/models/DongshengXiao_brain_bundary.hdf5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thn2P21Rx0LB"
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 7_U-Net_model/DongshengXiao_unet_motif_based_functional_atlas.hdf5 MesoNet/mesonet/models/DongshengXiao_unet_motif_based_functional_atlas.hdf5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnudgt6I6FTx"
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 8_VoxelMorph_model/VoxelMorph_Motif_based_functional_map_model_transformed1000.h5 mesonet_inputs/voxelMorph_Motif_based_functional_map_model_transformed1000.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oGLDOuKtKqI"
      },
      "source": [
        "# Five ways to use MesoNet\n",
        "\n",
        "MesoNet can be used through five approaches:\n",
        "1. **Atlas to brain**: Given a pre-trained DeepLabCut model that was trained to associate anatomical landmarks with corresponding points on atlases of brain regions, register an atlas of brain regions to the fixed brain imaging data using affine transformations. This approach is useful if your data has common anatomical landmarks and is the most robust to variations in image quality and orientation within your data.\n",
        "2. **Brain to atlas**: Given a pre-trained DeepLabCut model that was trained to associate anatomical landmarks with corresponding points on atlases of brain regions, the brain imaging data to a fixed atlas of brain regions using affine transformations. This approach is useful if you would like to normalize your brain images to a common template based on anatomical landmarks.\n",
        "3. **Atlas to brain + sensory maps**: Given a pre-trained DeepLabCut model that was trained to associate anatomical landmarks with corresponding points on atlases of brain regions as well as a set of folders containing functional brain activity for that animal that is consistent across animals, register an atlas of brain regions to the fixed brain imaging data using affine transformations. This approach is useful if you have consistent peaks of functional activity across animals that you would like to use in the alignment processes.\n",
        "4. **Motif-based functional maps (MBFMs) + U-Net**: Given a pre-trained U-Net model that was trained to associate brain imaging data with atlases of brain regions, predict the locations of brain regions in the data without the use of landmarks. The brain imaging data should be motif-based functional maps (MBFMs) calculated using the associated MATLAB code (using seqNMF). This approach is useful if one wishes to mark functional regions based on more complex features of the data (e.g. a motif-based functional map) than landmarks.\n",
        "5. **Motif-based functional maps (MBFMs) + Brain-to-atlas + VoxelMorph**: Given a pre-trained VoxelMorph model that was trained to compute a non-linear transformation between a template functional brain atlas and brain image data, predict the locations of brain regions in the data. In particular, this approach can register each input brain image to a user-defined template functional atlas. The brain imaging data should be motif-based functional maps (MBFMs) calculated using the associated MATLAB code (using seqNMF). This approach is useful if your images are consistently oriented and you want to compare the predicted locations of brain regions across different images.\n",
        "\n",
        "We will now copy over some sample input images for each of these five pipelines from OSF to our inputs folder. If, instead, you would like to upload your own images create a folder inside `mesonet_inputs` and put your images inside that folder; then, skip the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpXToLmIKx3o"
      },
      "source": [
        "#@title Run this cell to fetch sample data from OSF\n",
        "%cd /content/\n",
        "!osf -p fy6e3 clone /content/mesonet_inputs/example_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hActhRFLDl9o"
      },
      "source": [
        "Now, input the information about your input and output images, as well as the U-Net and DeepLabCut models that you would like to use. The default values will use the test data that we've included in the MesoNet git repository (in `MesoNet/mesonet/tests/test_input`). If you're using your own input data, replace `input_filename` below with the name of a folder in `mesonet_inputs` containing your input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXx8XqLH1wSb",
        "cellView": "form"
      },
      "source": [
        "#@title Input information for the model\n",
        "input_file_name = 'pipeline1_2'  #@param {type: \"string\"}\n",
        "input_file_sensory_raw_name = 'sensory_raw'  #@param {type: \"string\"}\n",
        "input_file_sensory_maps_name = 'sensory_maps'  #@param {type: \"string\"}\n",
        "input_file_MBFM_name = 'pipeline4_MBFM-U-Net'  #@param {type: \"string\"}\n",
        "input_file_voxelmorph_name = 'pipeline5_VoxelMorph'  #@param {type: \"string\"}\n",
        "\n",
        "output_file_atlas_brain_name = 'mesonet_outputs_atlas_brain'  #@param {type: \"string\"}\n",
        "output_file_brain_atlas_name = 'mesonet_outputs_brain_atlas'  #@param {type: \"string\"}\n",
        "output_file_sensory_name = 'mesonet_outputs_sensory'  #@param {type: \"string\"}\n",
        "output_file_MBFM_U_Net_name = 'mesonet_outputs_MBFM_U_Net'  #@param {type: \"string\"}\n",
        "output_file_voxelmorph_name = 'mesonet_outputs_voxelmorph'  #@param {type: \"string\"}\n",
        "\n",
        "model_name = 'DongshengXiao_brain_bundary.hdf5' #@param {type: \"string\"}\n",
        "u_net_only_model_name = 'DongshengXiao_unet_motif_based_functional_atlas.hdf5'\n",
        "dlc_model_name = 'atlas-DongshengXiao-2020-08-03'  #@param {type: \"string\"}\n",
        "voxelmorph_model_name = 'voxelMorph_Motif_based_functional_map_model_transformed1000.h5'  #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO5rzOEE20vz"
      },
      "source": [
        "# Set up filepaths based on your inputs\n",
        "input_path_root = os.path.join('/content','mesonet_inputs', 'example_data')\n",
        "input_file = os.path.join(input_path_root, 'osfstorage', 'Automated_pipeline_sample_data', input_file_name)\n",
        "input_file_sensory_raw = os.path.join(input_path_root, \n",
        "                                      'osfstorage', 'Automated_pipeline_sample_data', 'pipeline3_sensory', input_file_sensory_raw_name)\n",
        "input_file_sensory_maps = os.path.join(input_path_root, \n",
        "                                       'osfstorage', 'Automated_pipeline_sample_data', 'pipeline3_sensory', input_file_sensory_maps_name)\n",
        "input_file_MBFM = os.path.join(input_path_root, \n",
        "                               'osfstorage', 'Automated_pipeline_sample_data', input_file_MBFM_name)\n",
        "input_file_voxelmorph = os.path.join(input_path_root, \n",
        "                                     'osfstorage', 'Automated_pipeline_sample_data', input_file_voxelmorph_name)\n",
        "\n",
        "output_file_atlas_brain = os.path.join('/content','mesonet_outputs', output_file_atlas_brain_name)\n",
        "output_file_brain_atlas = os.path.join('/content','mesonet_outputs', output_file_brain_atlas_name)\n",
        "output_file_sensory = os.path.join('/content','mesonet_outputs', output_file_sensory_name)\n",
        "output_file_MBFM_U_Net = os.path.join('/content','mesonet_outputs', output_file_MBFM_U_Net_name)\n",
        "output_file_voxelmorph = os.path.join('/content','mesonet_outputs', output_file_voxelmorph_name)\n",
        "\n",
        "model = os.path.join('/content', 'MesoNet', 'mesonet', 'models', model_name)\n",
        "u_net_only_model = os.path.join('/content', 'MesoNet', 'mesonet', 'models', u_net_only_model_name)\n",
        "voxelmorph_model = os.path.join('/content','mesonet_inputs', voxelmorph_model_name)\n",
        "dlc_config = os.path.join('/content','mesonet_inputs', dlc_model_name, 'config.yaml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hv6LzKSC_v8"
      },
      "source": [
        "!mkdir '/content/mesonet_outputs'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_atlas_brain'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_brain_atlas'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_sensory'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_MBFM_U_Net'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_voxelmorph'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLul3lSb3WmY"
      },
      "source": [
        "Now that we've told Colab where to find the input and output folders, let's define the configuration file!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM1CKImF0OSo"
      },
      "source": [
        "# Configure MesoNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQiL1hPwhDrh"
      },
      "source": [
        "NOTE: If you get the error `ModuleNotFoundError: No module named 'mesonet'`, rerun the cell near the top of the notebook that starts with `%cd MesoNet/`, as well as the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_x_r_X2SLXS"
      },
      "source": [
        "# Set this environment variable to help MesoNet find the git repo location\n",
        "os.environ[\"MESONET_GIT\"]='/content/MesoNet/mesonet/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tbS1rlK3Osl"
      },
      "source": [
        "# We need to make sure that DeepLabCut doesn't run with a GUI (which isn't\n",
        "# supported in Colab).\n",
        "os.environ[\"DLClight\"]=\"True\"\n",
        "\n",
        "# Import mesonet and define the configuration file for each pipeline\n",
        "import mesonet\n",
        "## 1. Atlas to brain\n",
        "# Atlas-to-brain warp with U-Net and DeepLabCut\n",
        "print('1. Atlas-to-brain warp with U-Net and DeepLabCut')\n",
        "config_file_atlas_brain = mesonet.config_project(input_file, output_file_atlas_brain, 'test', \n",
        "                                                 atlas_to_brain_align=True, use_voxelmorph=False, \n",
        "                                                 use_unet=True, use_dlc=True, sensory_match=False, \n",
        "                                                 mat_save=False, olfactory_check=True,\n",
        "                                                 config=dlc_config, model=model)\n",
        "\n",
        "## 2. Brain to atlas\n",
        "# Brain-to-atlas warp with DeepLabCut\n",
        "print('2. Brain-to-atlas warp with DeepLabCut')\n",
        "config_file_brain_atlas = mesonet.config_project(input_file, output_file_brain_atlas, 'test', \n",
        "                                                 atlas_to_brain_align=False, use_voxelmorph=False, \n",
        "                                                 use_unet=True, use_dlc=True, sensory_match=False, \n",
        "                                                 mat_save=False, olfactory_check=True, \n",
        "                                                 config=dlc_config, model=model)\n",
        "\n",
        "## 3. Atlas to brain + sensory\n",
        "# Atlas-to-brain warp with U-Net, DeepLabCut, and sensory maps\n",
        "print('3. Atlas-to-brain warp with U-Net, DeepLabCut, and sensory maps')\n",
        "config_file_sensory = mesonet.config_project(input_file_sensory_raw, output_file_sensory, 'test',\n",
        "                                             atlas_to_brain_align=True, use_voxelmorph=False, \n",
        "                                             use_unet=True, use_dlc=True, sensory_match=True, \n",
        "                                             sensory_path=input_file_sensory_maps, mat_save=False, \n",
        "                                             config=dlc_config, model=model)\n",
        "\n",
        "## 4. MBFM + U-Net\n",
        "# Motif-based functional maps (MBFMs) with atlas directly applied using U-Net\n",
        "print('4. Motif-based functional maps (MBFMs) with atlas directly applied using U-Net')\n",
        "config_file_MBFM_U_Net = mesonet.config_project(input_file_MBFM, output_file_MBFM_U_Net, 'test', \n",
        "                                                atlas_to_brain_align=True, use_voxelmorph=False, \n",
        "                                                use_unet=True, use_dlc=False, sensory_match=False, \n",
        "                                                mat_save=False, mask_generate=False, \n",
        "                                                config=dlc_config, model=u_net_only_model)\n",
        "\n",
        "## 5. VoxelMorph\n",
        "# Local deformation warp with VoxelMorph and DeepLabCut\n",
        "print('5. Local deformation warp with VoxelMorph and DeepLabCut')\n",
        "config_file_voxelmorph = mesonet.config_project(input_file_voxelmorph, output_file_voxelmorph, 'test', \n",
        "                                                atlas_to_brain_align=False, use_voxelmorph=True, \n",
        "                                                use_unet=True, use_dlc=True, sensory_match=False, mat_save=False, \n",
        "                                                config=dlc_config, model=model, \n",
        "                                                align_once=True, olfactory_check=True, \n",
        "                                                voxelmorph_model=voxelmorph_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wmSornuIcWr"
      },
      "source": [
        "The config file (by default in each of the output folders) contains information about how MesoNet will run for each pipeline. We'll be using these config files as an input to the last two functions needed to run MesoNet. \n",
        "\n",
        "Now, we will run each of the five pipelines in turn:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb16iWZm0T9_"
      },
      "source": [
        "# Run MesoNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6xYOJczyIUB"
      },
      "source": [
        "## Pipeline 1: Atlas-to-brain\n",
        "Firstly, we will identify the outer edges of the cortex:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uR1JWHR0Xa8"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nLe62A-843I"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file_atlas_brain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FhQX6a189Zc"
      },
      "source": [
        "Next, we will identify and use cortical landmarks to align the atlas to the brain:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdkZHKo70bKX"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg1NLh3E9QTY"
      },
      "source": [
        "mesonet.predict_dlc(config_file_atlas_brain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7lCpR53H3EO"
      },
      "source": [
        "Congratulations, you're all done with this first pipeline! You can now check the outputs in the `mesonet_output_atlas_brain` folder. The segmented brain data can be found in `mesonet_output_atlas_brain/output_overlay`.\n",
        "\n",
        "The following four pipelines will follow a similar pattern:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Bbzh6wzcCU"
      },
      "source": [
        "## Pipeline 2: Brain-to-atlas\n",
        "This time, we will directly identify and use cortical landmarks to align the brain to the atlas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT0hngL331wT"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gAq9qv733vc"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file_brain_atlas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E778cvgzngw"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2jjquarzp34"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_dlc(config_file_brain_atlas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74FqIOkDz-Qx"
      },
      "source": [
        "You can now check the outputs in the `mesonet_output_brain_atlas` folder. The segmented brain data can be found in `mesonet_output_brain_atlas/output_overlay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkXNc2Ap0Gaw"
      },
      "source": [
        "## Pipeline 3: Atlas-to-Brain + sensory\n",
        "Now, we return to the Brain-to-Atlas approach while also using peaks of functional activity that are common across animals as a further alignment step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxYqk3Qy1K-w"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgz-lh-w1N8m"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file_sensory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_9tcIor1PH1"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZC7PQ0c1Q2O"
      },
      "source": [
        "mesonet.predict_dlc(config_file_sensory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqdDUZHi1ecN"
      },
      "source": [
        "You can now check the outputs in the `mesonet_output_sensory` folder. The segmented brain data can be found in `mesonet_output_sensory/output_overlay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTFM4mFg19eE"
      },
      "source": [
        "## Pipeline 4: MBFM + U-Net\n",
        "Our input for this pipeline will be a set of motif-based functional maps (MBFMs) - brain images that summarize patterns of spatio-temporal activity that are common across animals. You can generate these using a MATLAB script running [seqNMF](https://github.com/FeeLab/seqNMF) - such a script is available in `4_Data_code/New_end_to_end_code` on our [OSF repository](https://osf.io/svztu/). We will then use a U-Net model to directly segment the brain image into functional regions - no need for atlas registration here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogr73HsT29_W"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmKekkzW3A4o"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file_MBFM_U_Net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FL5w9Zn3IPC"
      },
      "source": [
        "You can now check the outputs in the `mesonet_output_MBFM_U_Net` folder. The segmented brain data can be found in `mesonet_output_MBFM_U_Net/output_overlay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wn10Qar3WxY"
      },
      "source": [
        "## Pipeline 5: VoxelMorph\n",
        "Our input for this pipeline will be a raw brain image followed by an MBFM (see Pipeline 4 description for details). We will use VoxelMorph - a local deformation technique - to register the MBFM to an atlas based on a template image in the MesoNet repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8yk7XCg0InQ"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7F3yQSe0OjA"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file_voxelmorph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlR21DdB3yoC"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA75tW_u336F"
      },
      "source": [
        "mesonet.predict_dlc(config_file_voxelmorph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7j9mAAV4AC-"
      },
      "source": [
        "You can now check the outputs in the `mesonet_output_voxelmorph` folder. The segmented brain data can be found in `mesonet_output_voxelmorph/output_overlay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjHOCd9f5DgV"
      },
      "source": [
        "# Conclusion\n",
        "These five pipelines can be directly accessed in the graphical user interface (GUI) that is available for MesoNet for ease of use. Furthermore, you can customize your pipeline by changing the options defined in `mesonet.config_project` for the CLI and in the GUI - you can use our [Quick Start Guide](https://github.com/bf777/MesoNet/wiki/Quick-Start-Guide) and [Config File Guide](https://github.com/bf777/MesoNet/wiki/Config-File-Guide) for guidance."
      ]
    }
  ]
}