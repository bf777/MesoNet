{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mesonet_demo_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14ZoP1l75j5tW8fJx4kMu42FA4t2Jq0l0",
      "authorship_tag": "ABX9TyOUYlIHPxXhYbaeJbpeKL/X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf777/MesoNet/blob/master/mesonet_demo_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBeYLFh1y43a"
      },
      "source": [
        "# MesoNet\n",
        "Welcome to MesoNet, a toolbox for segmenting mesoscale calcium images! This notebook will take you through all the steps needed to process your own calcium imaging dataset using our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ySs_sMAzwMo",
        "outputId": "953fff57-086c-4615-a68e-5d5c8af1dc0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Clone MesoNet repository\n",
        "!git clone https://github.com/bf777/MesoNet.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MesoNet'...\n",
            "remote: Enumerating objects: 1150, done.\u001b[K\n",
            "remote: Counting objects: 100% (603/603), done.\u001b[K\n",
            "remote: Compressing objects: 100% (461/461), done.\u001b[K\n",
            "remote: Total 1150 (delta 356), reused 356 (delta 136), pack-reused 547\u001b[K\n",
            "Receiving objects: 100% (1150/1150), 7.34 MiB | 25.14 MiB/s, done.\n",
            "Resolving deltas: 100% (740/740), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWqA1QrmVu5U"
      },
      "source": [
        "# Prepare inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utG7t2c7JTqv"
      },
      "source": [
        "!mkdir /content/mesonet_inputs/\n",
        "!mkdir /content/mesonet_inputs/pipeline1_2/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgL7qiElE8O8",
        "outputId": "9e2d2365-e56e-46bb-bfd6-0064bf37af0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd MesoNet/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MesoNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFZjRHCPvUL4",
        "outputId": "f0b161f2-2ae5-4864-b2b2-6ae0883c136e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Utility to install mesonet package and associated requirements (will be replaced with pip later)\n",
        "!pip install matplotlib==3.1.3\n",
        "\n",
        "# Install DeepLabCut for pose estimation\n",
        "!pip install deeplabcut"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib==3.1.3\n",
            "  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 90 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting deeplabcut\n",
            "  Downloading deeplabcut-2.2-py3-none-any.whl (540 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 540 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.3.5)\n",
            "Collecting ruamel.yaml>=0.15.0\n",
            "  Downloading ruamel.yaml-0.17.10-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 66.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.19.5)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.4.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (5.5.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.51.2)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (7.1.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.1.5)\n",
            "Collecting statsmodels>=0.11\n",
            "  Downloading statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.1.3)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.22.2.post1)\n",
            "Collecting tensorpack\n",
            "  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.5.0)\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 45.8 MB/s \n",
            "\u001b[?25hCollecting scikit-image>=0.17\n",
            "  Downloading scikit_image-0.18.2-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 50 kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.5.1)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.9)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 48 kB/s \n",
            "\u001b[?25hCollecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 36.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->deeplabcut) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->deeplabcut) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->deeplabcut) (1.15.0)\n",
            "Collecting ruamel.yaml.clib>=0.1.2\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (1.1.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (2021.7.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (2.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deeplabcut) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deeplabcut) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deeplabcut) (1.3.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->deeplabcut) (4.4.2)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11->deeplabcut) (0.5.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.3.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.36.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.12.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.34.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.17.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.0->deeplabcut) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (57.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (3.1.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->deeplabcut) (1.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug->deeplabcut) (4.1.2.30)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.0->deeplabcut) (3.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->deeplabcut) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->deeplabcut) (0.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->deeplabcut) (0.34.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->deeplabcut) (0.7.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deeplabcut) (1.0.1)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from tables->deeplabcut) (2.7.3)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (1.0.2)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (22.1.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (0.8.9)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (5.4.8)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110475 sha256=be8a3bf23c6f889f589898f75329cf4cd86d100d527ee15a8e69667578d2b113\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/e0/ee/a2b3c5caab3418c1ccd8c4de573d4cbe13315d7e8b0a55fbc2\n",
            "Successfully built filterpy\n",
            "Installing collected packages: scikit-image, ruamel.yaml.clib, msgpack-numpy, tf-slim, tensorpack, statsmodels, ruamel.yaml, opencv-python-headless, filterpy, deeplabcut\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed deeplabcut-2.2 filterpy-1.4.5 msgpack-numpy-0.4.7.1 opencv-python-headless-4.5.3.56 ruamel.yaml-0.17.10 ruamel.yaml.clib-0.2.6 scikit-image-0.18.2 statsmodels-0.12.2 tensorpack-0.11 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcmr-pE1yR75",
        "outputId": "69047af5-aec7-4bfc-c4dd-b665decec95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install MesoNet\n",
        "!python setup.py install\n",
        "\n",
        "# Reinstall OpenCV to address compatibility issue\n",
        "!pip install opencv-python==4.4.0.46\n",
        "\n",
        "# Reinstall h5py\n",
        "!pip install h5py==2.10.0\n",
        "\n",
        "# pip install mesonet"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mesonet.egg-info\n",
            "writing mesonet.egg-info/PKG-INFO\n",
            "writing dependency_links to mesonet.egg-info/dependency_links.txt\n",
            "writing requirements to mesonet.egg-info/requires.txt\n",
            "writing top-level names to mesonet.egg-info/top_level.txt\n",
            "writing manifest file 'mesonet.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'mesonet.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/mesonet\n",
            "copying mesonet/gui_train.py -> build/lib/mesonet\n",
            "copying mesonet/data.py -> build/lib/mesonet\n",
            "copying mesonet/voxelmorph_align.py -> build/lib/mesonet\n",
            "copying mesonet/atlas_brain_matching.py -> build/lib/mesonet\n",
            "copying mesonet/mask_functions.py -> build/lib/mesonet\n",
            "copying mesonet/gui_start.py -> build/lib/mesonet\n",
            "copying mesonet/img_augment.py -> build/lib/mesonet\n",
            "copying mesonet/utils.py -> build/lib/mesonet\n",
            "copying mesonet/gui_test.py -> build/lib/mesonet\n",
            "copying mesonet/dlc_predict.py -> build/lib/mesonet\n",
            "copying mesonet/__init__.py -> build/lib/mesonet\n",
            "copying mesonet/model.py -> build/lib/mesonet\n",
            "copying mesonet/predict_regions.py -> build/lib/mesonet\n",
            "copying mesonet/train_model.py -> build/lib/mesonet\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/gui_train.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/data.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/voxelmorph_align.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/atlas_brain_matching.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/mask_functions.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/gui_start.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/img_augment.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/utils.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/gui_test.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/dlc_predict.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/__init__.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/model.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/predict_regions.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "copying build/lib/mesonet/train_model.py -> build/bdist.linux-x86_64/egg/mesonet\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/gui_train.py to gui_train.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/data.py to data.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/voxelmorph_align.py to voxelmorph_align.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/atlas_brain_matching.py to atlas_brain_matching.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/mask_functions.py to mask_functions.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/gui_start.py to gui_start.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/img_augment.py to img_augment.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/gui_test.py to gui_test.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/dlc_predict.py to dlc_predict.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/predict_regions.py to predict_regions.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mesonet/train_model.py to train_model.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mesonet.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mesonet.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mesonet.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mesonet.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mesonet.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/mesonet-1.0.4.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mesonet-1.0.4.1-py3.7.egg\n",
            "Copying mesonet-1.0.4.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding mesonet 1.0.4.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mesonet-1.0.4.1-py3.7.egg\n",
            "Processing dependencies for mesonet==1.0.4.1\n",
            "Searching for neurite\n",
            "Reading https://pypi.org/simple/neurite/\n",
            "Downloading https://files.pythonhosted.org/packages/a0/4b/705ff365b11bef90b73f5f680c66e34eb3053a7e9ab2bb0705be7b854f08/neurite-0.1-py3-none-any.whl#sha256=22dbeff782106bd5b07ed64d408f1313e63345717166bd2224934a6676529bbc\n",
            "Best match: neurite 0.1\n",
            "Processing neurite-0.1-py3-none-any.whl\n",
            "Installing neurite-0.1-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding neurite 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/neurite-0.1-py3.7.egg\n",
            "Searching for voxelmorph\n",
            "Reading https://pypi.org/simple/voxelmorph/\n",
            "Downloading https://files.pythonhosted.org/packages/3c/77/fdcf9ff2c8450d447ba760122b50575cfc037921b5870dac61c04a4609cc/voxelmorph-0.1-py3-none-any.whl#sha256=ec83b4d0d1857b2b3f15499f88355d3026f32b5867df609ad5a6f96fe5cd942f\n",
            "Best match: voxelmorph 0.1\n",
            "Processing voxelmorph-0.1-py3-none-any.whl\n",
            "Installing voxelmorph-0.1-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding voxelmorph 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/voxelmorph-0.1-py3.7.egg\n",
            "Searching for python-polylabel\n",
            "Reading https://pypi.org/simple/python-polylabel/\n",
            "Downloading https://files.pythonhosted.org/packages/46/72/c0af9eaf4d4e3f1bfd6035bee76fe7ee8eda8bc9747f9e241bfb937eee82/python_polylabel-0.6-py3-none-any.whl#sha256=d4043cf453025f2f3ffd11eb0a4170ba3575e047ac9de7dec548e7d54e015cc1\n",
            "Best match: python-polylabel 0.6\n",
            "Processing python_polylabel-0.6-py3-none-any.whl\n",
            "Installing python_polylabel-0.6-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding python-polylabel 0.6 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/python_polylabel-0.6-py3.7.egg\n",
            "Searching for opencv-python==4.4.0.46\n",
            "Reading https://pypi.org/simple/opencv-python/\n",
            "Downloading https://files.pythonhosted.org/packages/1b/2d/62eba161d3d713e1720504de1c25d439b02c85159804d9ecead10be5d87e/opencv_python-4.4.0.46-cp37-cp37m-manylinux2014_x86_64.whl#sha256=f69a56e958ecb549ba84e0497a438080932b4d52ded441cec04d80afde71dc0a\n",
            "Best match: opencv-python 4.4.0.46\n",
            "Processing opencv_python-4.4.0.46-cp37-cp37m-manylinux2014_x86_64.whl\n",
            "Installing opencv_python-4.4.0.46-cp37-cp37m-manylinux2014_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding opencv-python 4.4.0.46 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/opencv_python-4.4.0.46-py3.7-linux-x86_64.egg\n",
            "Searching for keras==2.3.1\n",
            "Reading https://pypi.org/simple/keras/\n",
            "Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl#sha256=d08a57bd63546175f8f19232ba05906514d419da3e0af8ef7437fa1c11442e20\n",
            "Best match: Keras 2.3.1\n",
            "Processing Keras-2.3.1-py2.py3-none-any.whl\n",
            "Installing Keras-2.3.1-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding Keras 2.3.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/Keras-2.3.1-py3.7.egg\n",
            "Searching for numpy~=1.17.3\n",
            "Reading https://pypi.org/simple/numpy/\n",
            "Downloading https://files.pythonhosted.org/packages/b1/51/20098150b6108061cb7542af3de7bfcfe0182bca21613697153e49dc4adc/numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl#sha256=31db2f9604afbf897b23478942074bbbb2513467d2b4b4ac573a7b65c63c073c\n",
            "Best match: numpy 1.17.5\n",
            "Processing numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Installing numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding numpy 1.17.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/numpy-1.17.5-py3.7-linux-x86_64.egg\n",
            "Searching for pystrum\n",
            "Reading https://pypi.org/simple/pystrum/\n",
            "Downloading https://files.pythonhosted.org/packages/e4/3a/99e310f01f9e3ef4ab78d9e194c3b22bc53574c70c61c9c9bfc136161439/pystrum-0.1-py3-none-any.whl#sha256=31727c7a647fb372ddb95bca8ea3a79d7d7376f93253d936c5cf9e26aa41a13f\n",
            "Best match: pystrum 0.1\n",
            "Processing pystrum-0.1-py3-none-any.whl\n",
            "Installing pystrum-0.1-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pystrum 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pystrum-0.1-py3.7.egg\n",
            "Searching for keras-applications>=1.0.6\n",
            "Reading https://pypi.org/simple/keras-applications/\n",
            "Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl#sha256=df4323692b8c1174af821bf906f1e442e63fa7589bf0f1230a0b6bdc5a810c95\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Processing Keras_Applications-1.0.8-py3-none-any.whl\n",
            "Installing Keras_Applications-1.0.8-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/Keras_Applications-1.0.8-py3.7.egg\n",
            "error: numpy 1.17.5 is installed but numpy~=1.19.2 is required by {'tensorflow'}\n",
            "Collecting opencv-python==4.4.0.46\n",
            "  Downloading opencv_python-4.4.0.46-cp37-cp37m-manylinux2014_x86_64.whl (49.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.5 MB 38 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.4.0.46) (1.19.5)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\n",
            "mesonet 1.0.4.1 requires keras==2.3.1, but you have keras 2.4.3 which is incompatible.\n",
            "mesonet 1.0.4.1 requires numpy~=1.17.3, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.4.0.46\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
            "mesonet 1.0.4.1 requires keras==2.3.1, but you have keras 2.4.3 which is incompatible.\n",
            "mesonet 1.0.4.1 requires numpy~=1.17.3, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX2xRSlOG8BW"
      },
      "source": [
        "Because of how DeepLabCut operates, you now need to restart your runtime (under the Runtime menu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlkSR2Y1DMt-",
        "outputId": "ccfb8ee7-1fa6-4195-cf7d-a1a481380f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use tensorflow 1.x (supported by DeepLabCut)\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import os\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyqTdwum9zFL"
      },
      "source": [
        "We will now pull information from the OSF repository containing the DeepLabCut and U-Net models for our code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEycrQjx9yeS",
        "outputId": "abeca5ef-402d-45bb-ff61-854c14ce2b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install osfclient"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting osfclient\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from osfclient) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from osfclient) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from osfclient) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->osfclient) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->osfclient) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->osfclient) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->osfclient) (3.0.4)\n",
            "Installing collected packages: osfclient\n",
            "Successfully installed osfclient-0.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nHcGUo5-RZ6",
        "outputId": "55e69790-0a3c-434b-f5d5-255ad6839cc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 6_Landmark_estimation_model/atlas-DongshengXiao-2020-08-03.zip mesonet_inputs/atlas-DongshengXiao-2020-08-03.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "100% 643M/643M [00:05<00:00, 129Mbytes/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfMh09FNB8KX"
      },
      "source": [
        "!unzip -q mesonet_inputs/atlas-DongshengXiao-2020-08-03.zip -d /content/mesonet_inputs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmNgWKOJA4Ou",
        "outputId": "c206acd6-5104-497f-cc79-717b05e931eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 7_U-Net_model/DongshengXiao_brain_bundary.hdf5 MesoNet/mesonet/models/DongshengXiao_brain_bundary.hdf5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "100% 373M/373M [00:03<00:00, 105Mbytes/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thn2P21Rx0LB",
        "outputId": "29c32b9c-f501-4261-95c7-d933e3dbcee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 7_U-Net_model/DongshengXiao_unet_motif_based_functional_atlas.hdf5 MesoNet/mesonet/models/DongshengXiao_unet_motif_based_functional_atlas.hdf5"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "100% 373M/373M [00:02<00:00, 154Mbytes/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnudgt6I6FTx",
        "outputId": "73d4f672-43b6-4a29-9322-62520727094b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 8_VoxelMorph_model/VoxelMorph_Motif_based_functional_map_model_transformed1000.h5 mesonet_inputs/voxelMorph_Motif_based_functional_map_model_transformed1000.h5"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "100% 1.51M/1.51M [00:00<00:00, 141Mbytes/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oGLDOuKtKqI"
      },
      "source": [
        "# Five ways to use MesoNet\n",
        "\n",
        "MesoNet can be used through five approaches:\n",
        "1. **Atlas to brain**: Given a pre-trained DeepLabCut model that was trained to associate anatomical landmarks with corresponding points on atlases of brain regions, register an atlas of brain regions to the fixed brain imaging data using affine transformations. This approach is useful if your data has common anatomical landmarks and is the most robust to variations in image quality and orientation within your data.\n",
        "2. **Brain to atlas**: Given a pre-trained DeepLabCut model that was trained to associate anatomical landmarks with corresponding points on atlases of brain regions, the brain imaging data to a fixed atlas of brain regions using affine transformations. This approach is useful if you would like to normalize your brain images to a common template based on anatomical landmarks.\n",
        "3. **Atlas to brain + sensory maps**: Given a pre-trained DeepLabCut model that was trained to associate anatomical landmarks with corresponding points on atlases of brain regions as well as a set of folders containing functional brain activity for that animal that is consistent across animals, register an atlas of brain regions to the fixed brain imaging data using affine transformations. This approach is useful if you have consistent peaks of functional activity across animals that you would like to use in the alignment processes.\n",
        "4. **Motif-based functional maps (MBFMs) + U-Net**: Given a pre-trained U-Net model that was trained to associate brain imaging data with atlases of brain regions, predict the locations of brain regions in the data without the use of landmarks. The brain imaging data should be motif-based functional maps (MBFMs) calculated using the associated MATLAB code (using seqNMF). This approach is useful if one wishes to mark functional regions based on more complex features of the data (e.g. a motif-based functional map) than landmarks.\n",
        "5. **Motif-based functional maps (MBFMs) + Brain-to-atlas + VoxelMorph**: Given a pre-trained VoxelMorph model that was trained to compute a non-linear transformation between a template functional brain atlas and brain image data, predict the locations of brain regions in the data. In particular, this approach can register each input brain image to a user-defined template functional atlas. The brain imaging data should be motif-based functional maps (MBFMs) calculated using the associated MATLAB code (using seqNMF). This approach is useful if your images are consistently oriented and you want to compare the predicted locations of brain regions across different images.\n",
        "\n",
        "We will now copy over some sample input images for each of these five pipelines from OSF to our inputs folder. If, instead, you would like to upload your own images create a folder inside `mesonet_inputs` and put your images inside that folder; then, skip the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpXToLmIKx3o",
        "cellView": "form",
        "outputId": "c66c472b-1de6-4ee0-a4ec-f21a6e374e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Run this cell to fetch sample data from OSF\n",
        "\n",
        "%cd /content/\n",
        "# Pipeline 1 + 2\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline1_2/0.png mesonet_inputs/pipeline1_2/0.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline1_2/1.png mesonet_inputs/pipeline1_2/1.png\n",
        "\n",
        "# Pipeline 3\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/1/tail.png mesonet_inputs/pipeline3_sensory/sensory_maps/1/tail.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/1/visual.png mesonet_inputs/pipeline3_sensory/sensory_maps/1/visual.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/1/whisker.png mesonet_inputs/pipeline3_sensory/sensory_maps/1/whisker.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/2/tail.png mesonet_inputs/pipeline3_sensory/sensory_maps/2/tail.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/2/visual.png mesonet_inputs/pipeline3_sensory/sensory_maps/2/visual.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/2/whisker.png mesonet_inputs/pipeline3_sensory/sensory_maps/2/whisker.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/3/tail.png mesonet_inputs/pipeline3_sensory/sensory_maps/3/tail.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/3/visual.png mesonet_inputs/pipeline3_sensory/sensory_maps/3/visual.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_maps/3/whisker.png mesonet_inputs/pipeline3_sensory/sensory_maps/3/whisker.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_raw/1.png mesonet_inputs/pipeline3_sensory/sensory_raw/1.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_raw/2.png mesonet_inputs/pipeline3_sensory/sensory_raw/2.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline3_sensory/sensory_raw/3.png mesonet_inputs/pipeline3_sensory/sensory_raw/3.png\n",
        "\n",
        "# Pipeline 4\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline4_MBFM-U-Net/0.png mesonet_inputs/pipeline4_MBFM-U-Net/0.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline4_MBFM-U-Net/1.png mesonet_inputs/pipeline4_MBFM-U-Net/1.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline4_MBFM-U-Net/2.png mesonet_inputs/pipeline4_MBFM-U-Net/2.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline4_MBFM-U-Net/3.png mesonet_inputs/pipeline4_MBFM-U-Net/3.png\n",
        "\n",
        "# Pipeline 5\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline5_VoxelMorph/0.png mesonet_inputs/pipeline5_VoxelMorph/0.png\n",
        "!osf -p svztu fetch 0_Example_data/Automated_pipeline_sample_data/pipeline5_VoxelMorph/1.png mesonet_inputs/pipeline5_VoxelMorph/1.png"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "100% 6.88k/6.88k [00:00<00:00, 17.3Mbytes/s]\n",
            "100% 7.04k/7.04k [00:00<00:00, 16.8Mbytes/s]\n",
            "100% 137k/137k [00:00<00:00, 76.4Mbytes/s]\n",
            "100% 127k/127k [00:00<00:00, 80.0Mbytes/s]\n",
            "100% 128k/128k [00:00<00:00, 50.8Mbytes/s]\n",
            "100% 135k/135k [00:00<00:00, 73.2Mbytes/s]\n",
            "100% 120k/120k [00:00<00:00, 52.7Mbytes/s]\n",
            "100% 126k/126k [00:00<00:00, 74.1Mbytes/s]\n",
            "100% 157k/157k [00:00<00:00, 85.5Mbytes/s]\n",
            "100% 167k/167k [00:00<00:00, 76.8Mbytes/s]\n",
            "100% 146k/146k [00:00<00:00, 73.9Mbytes/s]\n",
            "100% 13.4k/13.4k [00:00<00:00, 31.2Mbytes/s]\n",
            "100% 13.8k/13.8k [00:00<00:00, 28.0Mbytes/s]\n",
            "100% 13.8k/13.8k [00:00<00:00, 31.4Mbytes/s]\n",
            "100% 19.5k/19.5k [00:00<00:00, 34.2Mbytes/s]\n",
            "100% 21.3k/21.3k [00:00<00:00, 32.6Mbytes/s]\n",
            "100% 21.0k/21.0k [00:00<00:00, 35.0Mbytes/s]\n",
            "100% 19.6k/19.6k [00:00<00:00, 34.8Mbytes/s]\n",
            "100% 6.88k/6.88k [00:00<00:00, 16.6Mbytes/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hActhRFLDl9o"
      },
      "source": [
        "Now, input the information about your input and output images, as well as the U-Net and DeepLabCut models that you would like to use. The default values will use the test data that we've included in the MesoNet git repository (in `MesoNet/mesonet/tests/test_input`). If you're using your own input data, replace `input_filename` below with the name of a folder in `mesonet_inputs` containing your input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXx8XqLH1wSb",
        "cellView": "form"
      },
      "source": [
        "#@title Input information for the model\n",
        "input_file_name = 'pipeline1_2'  #@param {type: \"string\"}\n",
        "input_file_sensory_raw_name = 'sensory_raw'  #@param {type: \"string\"}\n",
        "input_file_sensory_maps_name = 'sensory_maps'  #@param {type: \"string\"}\n",
        "input_file_MBFM_name = 'pipeline4_MBFM-U-Net'  #@param {type: \"string\"}\n",
        "input_file_voxelmorph_name = 'pipeline5_VoxelMorph'  #@param {type: \"string\"}\n",
        "\n",
        "output_file_atlas_brain_name = 'mesonet_outputs_atlas_brain'  #@param {type: \"string\"}\n",
        "output_file_brain_atlas_name = 'mesonet_outputs_brain_atlas'  #@param {type: \"string\"}\n",
        "output_file_sensory_name = 'mesonet_outputs_sensory'  #@param {type: \"string\"}\n",
        "output_file_MBFM_U_Net_name = 'mesonet_outputs_MBFM_U_Net'  #@param {type: \"string\"}\n",
        "output_file_voxelmorph_name = 'mesonet_outputs_voxelmorph'  #@param {type: \"string\"}\n",
        "\n",
        "model_name = 'DongshengXiao_brain_bundary.hdf5' #@param {type: \"string\"}\n",
        "u_net_only_model_name = 'DongshengXiao_unet_motif_based_functional_atlas.hdf5'\n",
        "dlc_model_name = 'atlas-DongshengXiao-2020-08-03'  #@param {type: \"string\"}\n",
        "voxelmorph_model_name = 'voxelMorph_Motif_based_functional_map_model_transformed1000.h5'  #@param {type: \"string\"}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO5rzOEE20vz"
      },
      "source": [
        "# Set up filepaths based on your inputs\n",
        "input_file = os.path.join('/content','mesonet_inputs', input_file_name)\n",
        "input_file_sensory_raw = os.path.join('/content','mesonet_inputs', 'pipeline3_sensory', input_file_sensory_raw_name)\n",
        "input_file_sensory_maps = os.path.join('/content','mesonet_inputs', 'pipeline3_sensory', input_file_sensory_maps_name)\n",
        "input_file_MBFM = os.path.join('/content','mesonet_inputs', input_file_MBFM_name)\n",
        "input_file_voxelmorph = os.path.join('/content','mesonet_inputs', input_file_voxelmorph_name)\n",
        "\n",
        "output_file_atlas_brain = os.path.join('/content','mesonet_outputs', output_file_atlas_brain_name)\n",
        "output_file_brain_atlas = os.path.join('/content','mesonet_outputs', output_file_brain_atlas_name)\n",
        "output_file_sensory = os.path.join('/content','mesonet_outputs', output_file_sensory_name)\n",
        "output_file_MBFM_U_Net = os.path.join('/content','mesonet_outputs', output_file_MBFM_U_Net_name)\n",
        "output_file_voxelmorph = os.path.join('/content','mesonet_outputs', output_file_voxelmorph_name)\n",
        "\n",
        "model = os.path.join('/content', 'MesoNet', 'mesonet', 'models', model_name)\n",
        "u_net_only_model = os.path.join('/content', 'MesoNet', 'mesonet', 'models', u_net_only_model_name)\n",
        "voxelmorph_model = os.path.join('/content','mesonet_inputs', voxelmorph_model_name)\n",
        "dlc_config = os.path.join('/content','mesonet_inputs', dlc_model_name, 'config.yaml')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hv6LzKSC_v8",
        "outputId": "40b574db-2e4a-4e20-847f-0b3b89f44753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir '/content/mesonet_outputs'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_atlas_brain'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_brain_atlas'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_sensory'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_MBFM_U_Net'\n",
        "!mkdir '/content/mesonet_outputs/mesonet_outputs_voxelmorph'"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/mesonet_outputs’: File exists\n",
            "mkdir: cannot create directory ‘/content/mesonet_outputs/mesonet_outputs_atlas_brain’: File exists\n",
            "mkdir: cannot create directory ‘/content/mesonet_outputs/mesonet_outputs_brain_atlas’: File exists\n",
            "mkdir: cannot create directory ‘/content/mesonet_outputs/mesonet_outputs_sensory’: File exists\n",
            "mkdir: cannot create directory ‘/content/mesonet_outputs/mesonet_outputs_MBFM_U_Net’: File exists\n",
            "mkdir: cannot create directory ‘/content/mesonet_outputs/mesonet_outputs_voxelmorph’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLul3lSb3WmY"
      },
      "source": [
        "Now that we've told Colab where to find the input and output folders, let's define the configuration file!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM1CKImF0OSo"
      },
      "source": [
        "# Configure MesoNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_x_r_X2SLXS"
      },
      "source": [
        "# Set this environment variable to help MesoNet find the git repo location\n",
        "os.environ[\"MESONET_GIT\"]='/content/MesoNet/mesonet/'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMQTnzPGu8DF"
      },
      "source": [
        "!ls /content/mesonet_outputs/mesonet_outputs_atlas_brain"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tbS1rlK3Osl",
        "outputId": "de85c990-1127-4e3f-9dc5-d0f73634d04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "# We need to make sure that DeepLabCut doesn't run with a GUI (which isn't\n",
        "# supported in Colab).\n",
        "os.environ[\"DLClight\"]=\"True\"\n",
        "\n",
        "# Import mesonet and define the configuration file for each pipeline\n",
        "import mesonet\n",
        "## 1. Atlas to brain\n",
        "# Atlas-to-brain warp with U-Net and DeepLabCut\n",
        "print('1. Atlas-to-brain warp with U-Net and DeepLabCut')\n",
        "config_file_atlas_brain = mesonet.config_project(input_file, output_file_atlas_brain, 'test', \n",
        "                                                 atlas_to_brain_align=True, use_voxelmorph=False, \n",
        "                                                 use_unet=True, use_dlc=True, \n",
        "                                                 sensory_match=False, mat_save=False, \n",
        "                                                 config=dlc_config, model=model)\n",
        "\n",
        "## 2. Brain to atlas\n",
        "# Brain-to-atlas warp with DeepLabCut\n",
        "print('2. Brain-to-atlas warp with DeepLabCut')\n",
        "config_file_brain_atlas = mesonet.config_project(input_file, output_file_brain_atlas, 'test', \n",
        "                                                 atlas_to_brain_align=False, use_voxelmorph=False, \n",
        "                                                 use_unet=False, use_dlc=True, sensory_match=False, \n",
        "                                                 mat_save=False, olfactory_check=False, \n",
        "                                                 config=dlc_config)\n",
        "\n",
        "## 3. Atlas to brain + sensory\n",
        "# Atlas-to-brain warp with U-Net, DeepLabCut, and sensory maps\n",
        "print('3. Atlas-to-brain warp with U-Net, DeepLabCut, and sensory maps')\n",
        "config_file_sensory = mesonet.config_project(input_file_sensory_raw, output_file_sensory, 'test',\n",
        "                                             atlas_to_brain_align=True, use_voxelmorph=False, \n",
        "                                             use_unet=True, use_dlc=True, sensory_match=True, \n",
        "                                             sensory_path=input_file_sensory_maps, mat_save=False, \n",
        "                                             config=dlc_config, model=model)\n",
        "\n",
        "## 4. MBFM + U-Net\n",
        "# Motif-based functional maps (MBFMs) with atlas directly applied using U-Net\n",
        "print('4. Motif-based functional maps (MBFMs) with atlas directly applied using U-Net')\n",
        "config_file_MBFM_U_Net = mesonet.config_project(input_file_MBFM, output_file_MBFM_U_Net, 'test', \n",
        "                                                atlas_to_brain_align=True, use_voxelmorph=False, \n",
        "                                                use_unet=True, use_dlc=False, sensory_match=False, \n",
        "                                                mat_save=False, mask_generate=False, \n",
        "                                                config=dlc_config, model=u_net_only_model)\n",
        "\n",
        "## 5. VoxelMorph\n",
        "# Local deformation warp with VoxelMorph and DeepLabCut\n",
        "print('5. Local deformation warp with VoxelMorph and DeepLabCut')\n",
        "config_file_voxelmorph = mesonet.config_project(input_file_voxelmorph, output_file_voxelmorph, 'test', \n",
        "                                                atlas_to_brain_align=False, use_voxelmorph=True, \n",
        "                                                use_unet=True, use_dlc=True, sensory_match=False, mat_save=False, \n",
        "                                                config=dlc_config, model=model, \n",
        "                                                align_once=True, olfactory_check=True, \n",
        "                                                voxelmorph_model=voxelmorph_model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c7e4d953c77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import mesonet and define the configuration file for each pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmesonet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m## 1. Atlas to brain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Atlas-to-brain warp with U-Net and DeepLabCut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mesonet'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wmSornuIcWr"
      },
      "source": [
        "The config file (by default in each of the output folders) contains information about how MesoNet will run for each pipeline. We'll be using these config files as an input to the last two functions needed to run MesoNet. \n",
        "\n",
        "Now, we will run each of the five pipelines in turn:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb16iWZm0T9_"
      },
      "source": [
        "# Run MesoNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6xYOJczyIUB"
      },
      "source": [
        "## Pipeline 1: Atlas-to-brain\n",
        "Firstly, we will identify the outer edges of the cortex:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uR1JWHR0Xa8"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nLe62A-843I"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file_atlas_brain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FhQX6a189Zc"
      },
      "source": [
        "Next, we will identify and use cortical landmarks to align the atlas to the brain:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdkZHKo70bKX"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg1NLh3E9QTY"
      },
      "source": [
        "mesonet.predict_dlc(config_file_atlas_brain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7lCpR53H3EO"
      },
      "source": [
        "Congratulations, you're all done with this first pipeline! You can now check the outputs in the `mesonet_output_atlas_brain` folder. The segmented brain data can be found in `mesonet_output_atlas_brain/output_overlay`.\n",
        "\n",
        "The following four pipelines will follow a similar pattern:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Bbzh6wzcCU"
      },
      "source": [
        "## Pipeline 2: Brain-to-atlas\n",
        "This time, we will directly identify and use cortical landmarks to align the brain to the atlas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E778cvgzngw"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2jjquarzp34"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_dlc(config_file_brain_atlas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74FqIOkDz-Qx"
      },
      "source": [
        "You can now check the outputs in the `mesonet_output_brain_atlas` folder. The segmented brain data can be found in `mesonet_output_brain_atlas/output_overlay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkXNc2Ap0Gaw"
      },
      "source": [
        "## Pipeline 3: Atlas-to-Brain + sensory\n",
        "Now, we return to the Brain-to-Atlas approach while also using peaks of functional activity that are common across animals as a further alignment step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxYqk3Qy1K-w"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgz-lh-w1N8m"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file_sensory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_9tcIor1PH1"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZC7PQ0c1Q2O"
      },
      "source": [
        "mesonet.predict_dlc(config_file_sensory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqdDUZHi1ecN"
      },
      "source": [
        "You can now check the outputs in the `mesonet_output_sensory` folder. The segmented brain data can be found in `mesonet_output_sensory/output_overlay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTFM4mFg19eE"
      },
      "source": [
        "## Pipeline 4: MBFM + U-Net\n",
        "Our input for this pipeline will be a set of motif-based functional maps (MBFMs) - brain images that summarize patterns of spatio-temporal activity that are common across animals. You can generate these using a MATLAB script running [seqNMF](https://github.com/FeeLab/seqNMF) - such a script is available in `4_Data_code/New_end_to_end_code` on our [OSF repository](https://osf.io/svztu/). We will then use a U-Net model to directly segment the brain image into functional regions - no need for atlas registration here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogr73HsT29_W"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmKekkzW3A4o"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file_MBFM_U_Net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FL5w9Zn3IPC"
      },
      "source": [
        "You can now check the outputs in the `mesonet_output_MBFM_U_Net` folder. The segmented brain data can be found in `mesonet_output_MBFM_U_Net/output_overlay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wn10Qar3WxY"
      },
      "source": [
        "## Pipeline 5: VoxelMorph\n",
        "Our input for this pipeline will be a raw brain image followed by an MBFM (see Pipeline 4 description for details). We will use VoxelMorph - a local deformation technique - to register the MBFM to an atlas based on a template image in the MesoNet repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlR21DdB3yoC"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA75tW_u336F"
      },
      "source": [
        "mesonet.predict_dlc(config_file_voxelmorph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7j9mAAV4AC-"
      },
      "source": [
        "You can now check the outputs in the `mesonet_output_voxelmorph` folder. The segmented brain data can be found in `mesonet_output_voxelmorph/output_overlay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjHOCd9f5DgV"
      },
      "source": [
        "# Conclusion\n",
        "These five pipelines can be directly accessed in the graphical user interface (GUI) that is available for MesoNet for ease of use. Furthermore, you can customize your pipeline by changing the options defined in `mesonet.config_project` for the CLI and in the GUI - you can use our [Quick Start Guide](https://github.com/bf777/MesoNet/wiki/Quick-Start-Guide) and [Config File Guide](https://github.com/bf777/MesoNet/wiki/Config-File-Guide) for guidance."
      ]
    }
  ]
}