{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mesonet_demo_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "14ZoP1l75j5tW8fJx4kMu42FA4t2Jq0l0",
      "authorship_tag": "ABX9TyPSOXxuMC9RShHePO6mFWg6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf777/MesoNet/blob/master/mesonet_demo_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBeYLFh1y43a"
      },
      "source": [
        "# MesoNet\n",
        "Welcome to MesoNet, a toolbox for segmenting mesoscale calcium images! This notebook will take you through all the steps needed to process your own calcium imaging dataset using our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ySs_sMAzwMo"
      },
      "source": [
        "# Clone MesoNet repository\n",
        "!git clone https://github.com/bf777/MesoNet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWqA1QrmVu5U"
      },
      "source": [
        "## Prepare inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utG7t2c7JTqv"
      },
      "source": [
        "!mkdir /content/mesonet_inputs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfpjIDVdWjFz"
      },
      "source": [
        "Now, we will copy sample data (11 images) from the git repository to the inputs folder. If, instead, you would like to upload your own images create a folder inside `mesonet_inputs` and put your images inside that folder; then, skip the next cell. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv03SrDLJebo"
      },
      "source": [
        "# If you have your own input data that you've put into a subfolder under\n",
        "# mesonet_inputs, don't run this cell.\n",
        "%cp -r MesoNet/tests/test_input/ mesonet_inputs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgL7qiElE8O8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7bfd4df-bbcd-4af2-da14-a6e9a01764a9"
      },
      "source": [
        "%cd MesoNet/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MesoNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcmr-pE1yR75"
      },
      "source": [
        "# Utility to install mesonet package and associated requirements (will be replaced with pip later)\n",
        "!pip install matplotlib==3.1.3\n",
        "\n",
        "# Install DeepLabCut for pose estimation\n",
        "!pip install deeplabcut\n",
        "\n",
        "# Install MesoNet\n",
        "!python setup.py install\n",
        "\n",
        "# Reinstall OpenCV to address compatibility issue\n",
        "!pip install opencv-python==4.4.0.46\n",
        "\n",
        "# Reinstall h5py\n",
        "!pip install h5py==2.10.0\n",
        "\n",
        "# pip install mesonet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX2xRSlOG8BW"
      },
      "source": [
        "Because of how DeepLabCut operates, you now need to restart your runtime (under the Runtime menu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlkSR2Y1DMt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f40a4e-4554-4598-f7c2-9f85b4ba2843"
      },
      "source": [
        "# Use tensorflow 1.x (supported by DeepLabCut)\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import os\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyqTdwum9zFL"
      },
      "source": [
        "We will now pull information from the OSF repository containing the DeepLabCut and U-Net models for our code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEycrQjx9yeS"
      },
      "source": [
        "!pip install osfclient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nHcGUo5-RZ6"
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 6_Landmark_estimation_model/atlas-DongshengXiao-2020-08-03.zip mesonet_inputs/atlas-DongshengXiao-2020-08-03.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfMh09FNB8KX"
      },
      "source": [
        "!unzip -q mesonet_inputs/atlas-DongshengXiao-2020-08-03.zip -d /content/mesonet_inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmNgWKOJA4Ou"
      },
      "source": [
        "%cd /content/\n",
        "!osf -p svztu fetch 7_U-Net_model/DongshengXiao_brain_bundary.hdf5 MesoNet/mesonet/models/DongshengXiao_brain_bundary.hdf5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hActhRFLDl9o"
      },
      "source": [
        "Now, input the information about your input and output images, as well as the U-Net and DeepLabCut models that you would like to use. The default values will use the test data that we've included in the MesoNet git repository (in `MesoNet/mesonet/tests/test_input`). If you're using your own input data, replace `input_filename` below with the name of the folder in `mesonet_inputs` containing your input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXx8XqLH1wSb"
      },
      "source": [
        "#@title Input information for the model\n",
        "input_filename = 'test_input'  #@param {type: \"string\"}\n",
        "output_filename = 'mesonet_outputs'  #@param {type: \"string\"}\n",
        "model_name = 'DongshengXiao_brain_bundary.hdf5' #@param {type: \"string\"}\n",
        "dlc_model_name = 'atlas-DongshengXiao-2020-08-03'  #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO5rzOEE20vz"
      },
      "source": [
        "# Set up filepaths based on your inputs\n",
        "input_file = os.path.join('/content','mesonet_inputs', input_filename)\n",
        "output_file = os.path.join('/content', output_filename)\n",
        "model = os.path.join('/content', 'MesoNet', 'mesonet', 'models', model_name)\n",
        "dlc_config = os.path.join('/content','mesonet_inputs', dlc_model_name, \n",
        "                          'config.yaml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hv6LzKSC_v8"
      },
      "source": [
        "!mkdir '/content/mesonet_outputs/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLul3lSb3WmY"
      },
      "source": [
        "Now that we've told Colab where to find the input and output folders, let's define the configuration file!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM1CKImF0OSo"
      },
      "source": [
        "## Configure MesoNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_x_r_X2SLXS"
      },
      "source": [
        "# Set this environment variable to help MesoNet find the git repo location\n",
        "os.environ[\"MESONET_GIT\"]='/content/MesoNet/mesonet/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tbS1rlK3Osl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e94c366-40d5-4237-f150-56c7428482f2"
      },
      "source": [
        "# We need to make sure that DeepLabCut doesn't run with a GUI (which isn't\n",
        "# supported in Colab).\n",
        "os.environ[\"DLClight\"]=\"True\"\n",
        "\n",
        "# Import mesonet and define the configuration file according to your chosen\n",
        "# inputs\n",
        "import mesonet\n",
        "config_file = mesonet.config_project(input_file, output_file, 'test',\n",
        "                                     use_voxelmorph=False, \n",
        "                                     mat_save=False, config=dlc_config, \n",
        "                                     model=model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/MesoNet/mesonet/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wmSornuIcWr"
      },
      "source": [
        "The config file (by default in `mesonet_outputs`) contains information about how MesoNet will run. We'll be using this config file as an input to the last two functions needed to run MesoNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1zqPaHFIY1-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62f1642e-f804-4154-c9e1-7e30d83f6ef3"
      },
      "source": [
        "config_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/mesonet_outputs/mesonet_test_config.yaml'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVClkGs38bje"
      },
      "source": [
        "Next, we'll use the U-net model to identify the outer edges of the cortex:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb16iWZm0T9_"
      },
      "source": [
        "## Run MesoNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uR1JWHR0Xa8"
      },
      "source": [
        "### Predict regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nLe62A-843I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648b1b8d-987c-4be2-bcca-1ed2a1bac7b6"
      },
      "source": [
        "%cd /content/\n",
        "mesonet.predict_regions(config_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/MesoNet/mesonet/models/DongshengXiao_brain_bundary.hdf5\n",
            "/content/mesonet_inputs/test_input\n",
            "12/12 [==============================] - 11s 942ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FhQX6a189Zc"
      },
      "source": [
        "Lastly, we will identify and use cortical landmarks to align the atlas to the brain:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdkZHKo70bKX"
      },
      "source": [
        "### Predict landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg1NLh3E9QTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77fd80e5-d693-4a5b-eef6-0744d12cf951"
      },
      "source": [
        "mesonet.predict_dlc(config_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "/content/mesonet_inputs/test_input/0.png\n",
            "/content/mesonet_inputs/test_input/1.png\n",
            "/content/mesonet_inputs/test_input/2.png\n",
            "/content/mesonet_inputs/test_input/3.png\n",
            "/content/mesonet_inputs/test_input/4.png\n",
            "/content/mesonet_inputs/test_input/5.png\n",
            "/content/mesonet_inputs/test_input/6.png\n",
            "/content/mesonet_inputs/test_input/7.png\n",
            "/content/mesonet_inputs/test_input/8.png\n",
            "/content/mesonet_inputs/test_input/9.png\n",
            "/content/mesonet_inputs/test_input/10.png\n",
            "/content/mesonet_inputs/test_input/11.png\n",
            "Using snapshot-1030000 for model /content/mesonet_inputs/atlas-DongshengXiao-2020-08-03/dlc-models/iteration-2/atlasAug3-trainset95shuffle1\n",
            "Initializing ResNet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Analyzing all the videos in the directory...\n",
            "Starting to analyze %  /content/mesonet_outputs/dlc_output/tmp_video.mp4\n",
            "/content/mesonet_outputs/dlc_output  already exists!\n",
            "Loading  /content/mesonet_outputs/dlc_output/tmp_video.mp4\n",
            "Duration of video [s]:  0.4 , recorded with  30.0 fps!\n",
            "Overall # of frames:  12  found with (before cropping) frame dimensions:  512 512\n",
            "Starting to extract posture\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20it [00:01, 12.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving results in /content/mesonet_outputs/dlc_output...\n",
            "Saving csv poses!\n",
            "The videos are analyzed. Now your research can truly start! \n",
            " You can create labeled videos with 'create_labeled_video'\n",
            "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
            "/content/mesonet_outputs/dlc_output  already exists!\n",
            "Starting to process video: /content/mesonet_outputs/dlc_output/tmp_video.mp4\n",
            "Loading /content/mesonet_outputs/dlc_output/tmp_video.mp4 and data.\n",
            "No filtered data file found in /content/mesonet_outputs/dlc_output for video tmp_video and scorer DLC_resnet50_atlasAug3shuffle1_1030000.\n",
            "Landmark prediction complete!\n",
            "Performing first transformation of atlas 0...\n",
            "Performing second transformation of atlas 0...\n",
            "Performing first transformation of atlas 1...\n",
            "Performing second transformation of atlas 1...\n",
            "Performing first transformation of atlas 2...\n",
            "Performing second transformation of atlas 2...\n",
            "Performing first transformation of atlas 3...\n",
            "Performing second transformation of atlas 3...\n",
            "Performing first transformation of atlas 4...\n",
            "Performing second transformation of atlas 4...\n",
            "Performing first transformation of atlas 5...\n",
            "Performing second transformation of atlas 5...\n",
            "Performing first transformation of atlas 6...\n",
            "Performing second transformation of atlas 6...\n",
            "Performing first transformation of atlas 7...\n",
            "Performing second transformation of atlas 7...\n",
            "Performing first transformation of atlas 8...\n",
            "Performing second transformation of atlas 8...\n",
            "Performing first transformation of atlas 9...\n",
            "Performing second transformation of atlas 9...\n",
            "Performing first transformation of atlas 10...\n",
            "Performing second transformation of atlas 10...\n",
            "Performing first transformation of atlas 11...\n",
            "Performing second transformation of atlas 11...\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 0 saved!\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 1 saved!\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 2 saved!\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 3 saved!\n",
            "LEN CNTS: 41\n",
            "LEN LABELS: 41\n",
            "Mask 4 saved!\n",
            "LEN CNTS: 40\n",
            "LEN LABELS: 40\n",
            "Mask 5 saved!\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 6 saved!\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 7 saved!\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 8 saved!\n",
            "LEN CNTS: 43\n",
            "LEN LABELS: 43\n",
            "Mask 9 saved!\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 10 saved!\n",
            "LEN CNTS: 42\n",
            "LEN LABELS: 42\n",
            "Mask 11 saved!\n",
            "Analysis complete! Check the outputs in the folders of /content/mesonet_outputs/dlc_output/../output_overlay.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7lCpR53H3EO"
      },
      "source": [
        "Congratulations, you're all done! You can now check the outputs in the `mesonet_outputs` folder. The segmented brain data can be found in `mesonet_outputs/output_mask`!"
      ]
    }
  ]
}